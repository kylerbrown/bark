#! /bin/env python
#
# Michael Gibson 17 July 2015
# Kyler Brown December 2016
# Graham Fetterman July 2018, 2021

import os
import numpy as np

from bark.io.rhd.read_header import read_header
from bark.io.rhd.get_bytes_per_data_block import get_bytes_per_data_block
from bark.io.rhd.read_data_blocks import read_data_blocks, preallocate_memory
from bark.io.rhd.data_to_result import data_to_result

from . import constants as const

UINT16_BIT_OFFSET = int(2**15)

def read_data(filename, no_floats=False, max_memory=0):
    """Reads Intan Technologies RHD2000 data file generated by evaluation board GUI.

    Data are yielded in a dictionary, for future extensibility.

    A file's contents are split into chunks governed by max_memory.

    Args:
        filename (str): .rhd file name
        no_floats (bool): whether to avoid converting 16-bit integer values
                          to 32-bit floats (not converting saves disk space)
        max_memory (int): size of chunks to split file's data into (in bytes)

    Yields:
        dict: containing data fields and some metadata
        
    """

    fid = open(filename, 'rb')
    filesize = os.path.getsize(filename)

    header = read_header(fid)

    if header['notch_filter_frequency'] > 0:
        msg = ('Warning: a notch filter ({}Hz) was applied in the GUI, ' +
               'but has not been applied here.')
        print(msg.format(header['notch_filter_frequency']))

    channel_reporting = [('amplifier', 'num_amplifier_channels'),
                         ('auxiliary input', 'num_aux_input_channels'),
                         ('supply voltage', 'num_supply_voltage_channels'),
                         ('board ADC', 'num_board_adc_channels'),
                         ('board digital input', 'num_board_dig_in_channels'),
                         ('board digital output', 'num_board_dig_out_channels'),
                         ('temperature sensor', 'num_temp_sensor_channels')]
    for channel_name, channel_count_id in channel_reporting:
        print('Found {} {} channel{}.'.format(header[channel_count_id],
                                              channel_name,
                                              plural(header[channel_count_id])))
    print('')

    # Determine how many samples the data file contains.
    bytes_per_block = get_bytes_per_data_block(header)

    # How many data blocks remain in this file?
    data_present = False
    bytes_remaining = filesize - fid.tell()
    if bytes_remaining > 0:
        data_present = True

    if bytes_remaining % bytes_per_block != 0:
        msg = ('Something is wrong with file size: ' +
               'should have a whole number of data blocks')
        raise ValueError(msg)

    num_data_blocks = int(bytes_remaining / bytes_per_block)

    num_samples = header['num_samples_per_data_block']
    num_amplifier_samples = num_samples * num_data_blocks
    num_aux_input_samples = (num_samples // 4) * num_data_blocks
    num_supply_voltage_samples = 1 * num_data_blocks
    num_board_adc_samples = num_samples * num_data_blocks
    num_board_dig_in_samples = num_samples * num_data_blocks
    num_board_dig_out_samples = num_samples * num_data_blocks

    record_time = num_amplifier_samples / header['sample_rate']

    if data_present:
        print('File contains {:0.3f} seconds of data.'.format(record_time),
              'Amplifiers were sampled at',
              '{:0.2f} kHz.'.format(header['sample_rate'] / 1000))
    else:
        print('File contains no data. Amplifiers were sampled at',
              '{:0.2f} kHz.'.format(header['sample_rate'] / 1000))

    if data_present:
        # chunk_size governs how many datablocks are read in and then written
        # to file at once
        # minimum is 1 datablock, maximum is every datablock in the file
        # two copies of the chunk are in memory at once for some operations
        # (reformatting, changing dtypes), so max_memory is divided by 2
        chunk_size = min(max(int(0.5 * max_memory / bytes_per_block), 1),
                         num_data_blocks)
        chunks, remainder = divmod(num_data_blocks, chunk_size)
        data = preallocate_memory(header, chunk_size)
        for _ in range(chunks):
            read_data_blocks(data, header, fid, datablocks_per_chunk=chunk_size)
            yield check_data_and_reformat(header, data, no_floats)
        if remainder:
            data = preallocate_memory(header, remainder)
            read_data_blocks(data, header, fid, datablocks_per_chunk=remainder)
            yield check_data_and_reformat(header, data, no_floats)
        # Make sure we have read exactly the right amount of data.
        bytes_remaining = filesize - fid.tell()
        if bytes_remaining != 0:
            raise Exception('Error: End of file not reached.')
    else:
        yield data_to_result(header, {}, data_present)
    # Close data file.
    fid.close()

def check_data_and_reformat(header, data, no_floats):
    """Performs some cleanup on data and builds a dictionary to return.

    Args:
        header (dict): metadata for the data
        data (dict): different data fields are contained in numpy arrays
        no_floats (bool): whether to expand 16-bit ints into 32-bit floats

    Returns:
        dict: combining data and some metadata
    """
    extras = {}  # dictionary for extra parameters

    # Extract digital input channels to separate variables.
    for i in range(header['num_board_dig_in_channels']):
        mask = 1 << header['board_dig_in_channels'][i]['native_order']
        masked_bits = np.bitwise_and(data['board_dig_in_raw'], mask)
        data['board_dig_in_data'][i,:] = masked_bits.astype(np.bool)

    # Extract digital output channels to separate variables.
    for i in range(header['num_board_dig_out_channels']):
        mask = 1 << header['board_dig_out_channels'][i]['native_order']
        masked_bits = np.bitwise_and(data['board_dig_out_raw'], mask)
        data['board_dig_out_data'][i,:] = masked_bits.astype(np.bool)
    if no_floats:
        # record the bit voltage scaling level but do not apply to the data
        # converting to floats increases size 4x, which makes a big
        # difference at the terabyte+ level.
        extras['amplifier_bit_microvolts'] = const.AMPLIFIER_BIT_MICROVOLTS
        # numpy doesn't do over/underflow checks, so this actually works as intended
        np.subtract(data['amplifier_data'],
                    UINT16_BIT_OFFSET,
                    data['amplifier_data'],
                    casting='unsafe')
        data['amplifier_data'] = data['amplifier_data'].astype(np.int16,
                                                               copy=False)
        extras['aux_bit_volts'] = const.AUX_BIT_VOLTS
        extras['supply_bit_volts'] = const.SUPPLY_BIT_VOLTS
        extras['temp_bit_celcius'] = const.TEMP_BIT_CELCIUS

        if header['eval_board_mode'] == 1:
            extras['ADC_input_bit_volts'] = const.ADC_BIT_VOLTS_MODE_1
        elif header['eval_board_mode'] == 13:
            extra['ADC_input_bit_volts'] = const.ADC_BIT_VOLTS_MODE_13
        else:
            extras['ADC_input_bit_volts'] = const.ADC_BIT_VOLTS_MODE_0
        # underflow is intentional here as well
        np.subtract(data['board_adc_data'],
                    UINT16_BIT_OFFSET,
                    data['board_adc_data'],
                    casting='unsafe')
        data['board_adc_data'] = data['board_adc_data'].astype(np.int16,
                                                               copy=False)
    else:
        # Scale voltage levels appropriately.
        offset_amp_data = (data['amplifier_data'].astype(np.int32) -
                           UINT16_BIT_OFFSET)
        data['amplifier_data'] = np.multiply(const.AMPLIFIER_BIT_MICROVOLTS,
                                             offset_amp_data)  # units of microvolts
        data['aux_input_data'] = np.multiply(const.AUX_BIT_VOLTS,
                                             data['aux_input_data'])  # units of volts
        data['supply_voltage_data'] = np.multiply(const.SUPPLY_BIT_VOLTS,
                                                  data['supply_voltage_data'])  # units of volts
        if header['eval_board_mode'] == 1:
            offset_adc_data = (data['board_adc_data'].astype(np.int32) -
                               UINT16_BIT_OFFSET)
            data['board_adc_data'] = np.multiply(const.ADC_BIT_VOLTS_MODE_1,
                                                 offset_adc_data)  # units of volts
        elif header['eval_board_mode'] == 13:
            offset_adc_data = (data['board_adc_data'].astype(np.int32) -
                               UINT16_BIT_OFFSET)
            data['board_adc_data'] = np.multiply(const.ADC_BIT_VOLTS_MODE_13,
                                                 offset_adc_data) # units of volts
        else:
            data['board_adc_data'] = np.multiply(const.ADC_BIT_VOLTS_MODE_0,
                                                 data['board_adc_data'])  # units of volts
        data['temp_sensor_data'] = np.multiply(const.TEMP_BIT_CELCIUS,
                                               data['temp_sensor_data'])  # units of degrees C

    # Check for gaps in timestamps.
    num_gaps = np.sum(np.diff(data['t_amplifier']) != 1)
    if num_gaps != 0:
        print('Warning: {} gaps in timestamp data found.'.format(num_gaps),
              'Time scale will not be uniform!')

    # Scale time steps (units = seconds).
    data['t_amplifier'] = data['t_amplifier'] / header['sample_rate']
    data['t_aux_input'] = data['t_amplifier'][0:len(data['t_amplifier']):4]
    per_block = data['t_amplifier'][0:len(data['t_amplifier']):header['num_samples_per_data_block']]
    data['t_supply_voltage'] = per_block
    data['t_temp_sensor'] = per_block
    data['t_board_adc'] = data['t_amplifier']
    data['t_dig'] = data['t_amplifier']

    # Move variables to result struct.
    result = data_to_result(header, data, data_present=True)
    result.update(extras)
    return result


def plural(n):
    return '' if n == 1 else 's'
