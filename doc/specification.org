#-*- mode: org -*-
#+STARTUP:    align fold hidestars oddeven
#+TITLE:    Advanced Recording Format Specification (2.0.0)
#+AUTHOR:    Dan Meliza
#+EMAIL:     dan@meliza.org
#+DATE: [2013-02-08 Fri]
#+LANGUAGE:   en
#+OPTIONS: ^:nil H:2
#+STYLE:    <link rel="stylesheet" href="org.css" type="text/css" />

This document specifies a data container, the ARF file, which is designed to
hold electrophysiological, acoustic, and behavioral data along with associated
metadata and derived quantities in a hierarchical structure.

* Conceptual framework

Bioacoustic, electrophysiological, and behavioral data fall into two general
types:

+ sampled data :: A quantitative physical property of a system (e.g. sound
                  pressure or voltage) measured at discrete intervals. The
                  /sampling rate/ of the data is the number of times per second
                  the value is sampled.
+ event data :: A series of events taking place at discrete times. Event data
                are /simple/ if the events are identical except for the time
                they occurred (e.g. spike times). Event data are /complex/ if
                additional information is associated with the events; for
                example, stimulus presentation events are associated with
                stimulus identity and whether the stimulus is starting or stopping.

We define the concept of an /Entry/, which is an abstract grouping of data that
all start at the same time. The data can be of any type or quantity, and can be
unequal in length. For example, an entry can consist of the sound pressure
waveform of a bird singing and a set of intervals identifying the unique
syllables in the song.

* File format

ARF files shall be readable by the HDF5 library, version 1.8 or later.

ARF is based on the [[http://www.hdfgroup.org/HDF5/][HDF5 format]], which was developed by the National Center for
Supercomputing Applications. It is used in many scientific applications and is
extensively tested and documented. The HDF5 library supports automatic
conversion of data types, so if data are stored, for example, in 32-bit
big-endian integers, they can be accessed as 64-bit little-endian integers
transparently. By building ARF files in the HDF5 format, the data will remain
accessible on multiple architectures and hopefully for many years in the future.

HDF5 provides a generic hierarchical structure comprising groups and datasets,
either of which may have attributes. ARF specifies the layout used to store
data within this framework.

** Entries

Each /Entry/ in the file is represented by an HDF5 group. The group contains all
the data objects associated with that entry, stored as HDF5 datasets, and all
the metadata associated with the entry, stored as HDF5 attributes. The following
attributes are required:

+ timestamp ::  The start time of the entry. A two-element array with the first
                element the number of seconds since January 1, 1970, and the
                second the rest of the elapsed time, in microseconds. Must have
                at least 64-bit integer precision.
+ recid :: A unique ID for the entry. Points to an entry in an external
           database. The value 0 is reserved, and indicates an unknown or
           undefined ID. Must have at least 64-bit unsigned integer precision.

In addition, the following optional attributes are defined. They do not need to
be present in the group if not applicable, but if they are present they must
have a datatype with class =H5T_STRING=, of any size, with =STRPAD= set to
=H5T_STR_NULLTERM= (i.e. null-terminated), and =CTYPE= of =H5T_C_S1=. Encoding
must be ASCII or UTF-8.

+ animal :: Indicates the name or ID of the animal.
+ experimenter :: Indicates the name or ID of the experimenter.
+ protocol :: Optional comment field, indicating the treatment, stimulus, or any
              other user-specified comment.
+ recuri :: The URI of the external database referenced by =recid=.

** Datasets
   :PROPERTIES:
   :ID:       BB70AFB7-83F2-4FA6-8D03-02033BF1B7AF
   :END:

Each channel of data in an entry is represented by a separate HDF5 dataset.
The format of each dataset depends on the type of data it stores (see below),
but all datasets must have the following attributes:

+ units ::  Units of the channel data, preferably in SI notation. May be empty
            for sampled data if units are not known. Format is a =H5T_STRING=.
+ datatype ::  Indicates the source of data in the entry. Must have at least
               unsigned integer precision great enough to include all the values
               defined in [[id:A960F5BB-0E75-47B0-A477-380892DA7D5E][Datatypes]].

The following attributes are defined, but are optional or only required for
some data types.

+ sampling_rate :: A nonzero number indicating the sampling rate of the data, in
                   Hz. Required for sampled data, and for interval and event
                   data with units of samples. May be any numerical datatype.
+ offset :: Indicates the start time of the dataset relative to the start of the
            entry. For sampled data, the units must be samples. For event data
            types, the units must be the same as the units of the dataset.  May
            be any numerical type.  If missing, the offset is zero.

*** Sampled data

Sampled data is stored as an N-dimensional array of scalar values corresponding
to the measurement at each sampling interval. The first dimension of the array
corresponds to time. The significance of additional dimensions is unspecified.
The best practice is to use 1-D arrays for each channel.  The =sampling_rate=
attribute is required.

*** Event data

Event data can be stored in one of two formats. Simple event data should be
stored in a 1D array, with each element in the array indicating the time of the
event *relative to the start of the entry* (or dataset, if there is an offset).
Event arrays are distinguished from sampled data arrays by the =datatype= and
=units= attributes.

Complex event data must be stored as arrays with a compound datatype (i.e. with
multiple fields). Only one field is required, =start=, which indicates the time
of the event and can be any numerical type.

A special case of event data are intervals, which are defined by a start and
stop time. In previous versions of the specification, this was considered a
separate data type, with two additional required fields, =name= (a string) and
=stop= (a time).  Some programs may find it more convenient to store separate
onset and offset events.

*** Datatypes
    :PROPERTIES:
    :ID:       A960F5BB-0E75-47B0-A477-380892DA7D5E
    :END:

The =datatype= attribute is an integer code indicating the type of data in a
channel. It specifies how the data should be interpreted. The following values
are defined:

| value | name       | meaning                                              |
|-------+------------+------------------------------------------------------|
|     0 | UNDEFINED  | undefined or unknown                                 |
|     1 | ACOUSTIC   | acoustic                                             |
|     2 | EXTRAC_HP  | extracellular, high-pass (single-unit or multi-unit) |
|     3 | EXTRAC_LF  | extracellular, local-field                           |
|     4 | EXTRAC_EEG | extracellular, EEG                                   |
|     5 | INTRAC_CC  | intracellular, current-clamp                         |
|     6 | INTRAC_VC  | intracellular, voltage-clamp                         |
|  1000 | EVENT      | generic event times                                  |
|  1001 | SPIKET     | spike event times                                    |
|  1002 | BEHAVET    | behavioral event times                               |
|  2000 | INTERVAL   | generic intervals                                    |
|  2001 | STIMI      | stimulus presentation intervals                      |
|  2002 | COMPONENTL | component (e.g. motif) labels                        |

Values below 1000 are reserved for sampled data types.

** Extensions to the format

The above specification should be considered as a required minimum for a file to
be in ARF format. Additional attributes, groups, and datasets may be added, so
long as they do not conflict with any attributes required above. Such attributes
may be forwards incompatible with versions in which additional attributes are
defined, so it's recommended to prefix names with the name of the application.

*** Top-level datasets

ARF files may have datasets in the root group.  These are not associated with
any entry, but may contain additional metadata.  For example, data recording
software may keep a log of events.

* Changes to the specification

Because the ARF format is based on HDF5, data will remain accessible using
standard HDF5 tools even if the specifications change. Customized software may,
however, make assumptions about the organization of the data, and thus may fail
to work with later versions of the format. Changes that break backwards
compatibility (older software unable to read newer versions of the format)
include removing required fields and attributes. In keeping with the idea of
semantic versioning, such changes should receive new major version numbers.

** version 2.0

Event data was defined to include both "simple" and "complex" events.  Interval
data became a special case of complex event data.  This was to allow data
collection programs to store more information about events, without forcing
them to use the strictly defined data type for intervals.  The definition of
a distinct interval data type was dropped unceremoniously.  Software should
check for the existence of a 'stop' field.

The times for event data were no longer required to be in units of seconds, and
the format was not required to be double-precision floating point. The
sampling_rate attribute was required for event datasets where the units are in
samples.

Root-level datasets were explicitly allowed.

Semantic versioning was introduced.

** version 1.1

The ARF file format changed significantly, breaking both forward and backwards
compatibility (apologies to any serious semantic versioning afficianados). The
scope of the changes was justified (in the mind of the developer), even for a
minor version number, by the relatively limited use of the file format, and the
superior performance and simplicity of the new format.

A python-based migration tool (/arfmigrate/) was added for converting pre-1.1
files to the 1.1 format. This script modifies arf files in place, and can
compress data in the process.

+ Catalogs were removed at the top level and in entries. The objects themselves
  now carry all the metadata once in the catalog as attributes.
+ Multichannel datasets were deprecated in favor of multiple single-channel
  datasets. Channels should only be grouped into single datasets when the data
  are really inseparable (e.g. left and right channels). This greatly improved
  read performance, at some expense in file size.
+ Entry groups were deprecated; datasets that start at different times but need
  to be grouped together can be given an offset value indicating the interval
  between the entry start time and the start of the data.

The attributes required by pytables were deprecated.  Some interfaces may
continue to store them, but they are no longer required.
